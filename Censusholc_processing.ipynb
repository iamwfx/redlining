{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import glob\n",
    "import requests\n",
    "# from geoalchemy2 import Geometry, WKTElement\n",
    "\n",
    "import psycopg2  # (if it is postgres/postgis)\n",
    "conn = psycopg2.connect(database=\"postgres\", user=\"wenfeixu\", password=\"\",\n",
    "    host=\"localhost\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://wenfeixu:@localhost:5432/postgres')\n",
    "    \n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKIP IF ALREADY DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get the HOLC shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "select * from holc_all_dump_4326_new\n",
    "'''\n",
    "holc_all = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rough Join \n",
    "Create a convex hull to roughly get the correct census tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TopologyException: Input geom 1 is invalid: Self-intersection at or near point -89.651725004595761 39.816280327218124 at -89.651725004595761 39.816280327218124\n",
      "TopologyException: Input geom 1 is invalid: Self-intersection at or near point -78.890613000000002 36.014611000000002 at -78.890613000000002 36.014611000000002\n"
     ]
    }
   ],
   "source": [
    "holc_convex_hull = {}\n",
    "for x in holc_all.city.unique():\n",
    "    try: \n",
    "        holc_convex_hull[x]=holc_all[holc_all.city==x].geometry.unary_union.convex_hull\n",
    "    except ValueError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = {'init': 'epsg:4326'}\n",
    "holc_convex_hull = GeoDataFrame(pd.DataFrame(list(holc_convex_hull.keys())\n",
    "                                             , columns=['city']) , \n",
    "                                crs=crs, \n",
    "                                geometry=list(holc_convex_hull.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holc_convex_hull.to_file('data/holc/holc_convex_hull.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there were self-intersections and some weird hulls, I had to manually edit some of the hulls. Thus, we'll import the revised version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "holc_convex_hull = gpd.read_file('data/holc/holc_convex_hull_editted.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Join all census shapefiles to HOLC shapes\n",
    "All the shapefiles are in postGIS, so we'll do the calculations in there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years_list=[\n",
    "#     'us_tract_1930_conflated_4326',\n",
    "#             'us_tract_1940_conflated_4326',\n",
    "#             'us_tract_1950_conflated_4326',\n",
    "#             'us_tract_1960_conflated_4326',\n",
    "#            'us_tract_1970_conflated_4326',\n",
    "#            'us_tract_1980_conflated_4326',\n",
    "#            'us_blck_grp_1990_4326',\n",
    "#            'us_blck_grp_2000_4326',\n",
    "#            'us_blck_grp_2010_4326',]\n",
    "\n",
    "# def create_holc_shapes(table):\n",
    "#     sql = '''\n",
    "#         select a.*, b.holc_grade, b.city from {} as a\n",
    "#         inner join \n",
    "#         (select * from holc_all_4326 where is_valid='Valid Geometry') as b\n",
    "#         on st_intersects( a.geom, b.geom)\n",
    "#             '''.format(table)\n",
    "\n",
    "#     df = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )\n",
    "#     df.to_file('data/holc_census/shapefiles/{}.shp'.format(table))\n",
    "#     print(\"{} done\".format(table))\n",
    "    \n",
    "# for each in years_list: \n",
    "#     create_holc_shapes(each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each census is pretty different in each other, let's just do each year manually. From 1930 - 1980 we use census tracts, 1990 onwards are block groups.\n",
    "\n",
    "\n",
    "Also make sure to prep all the data here. This includes: \n",
    "- creating the 'other' (non-white, non-black) \n",
    "- adjusting the median income levels for inflation to 2016 levels.\n",
    "- aggregating levels categories when necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1930 \n",
    "Using census from that year. Has the following columns: \n",
    "- Population\n",
    "- Race by white, colored, other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the cities have their own file, so we'll need to join them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1930_1 = pd.read_csv('data/NHGIS/census_1930/nhgis0001_ds58_1930_tract.csv',index_col=None, header=0)\n",
    "census_1930_1 = census_1930_1.rename(columns={'BHI001':'population',\n",
    "                                          'BIQ001':'white_native',\n",
    "                                          'BIQ002':'white_foreignparents',\n",
    "                                          'BIQ003':'white_foreign',\n",
    "                                          'BIQ004':'colored',\n",
    "                                        'BIQ005':'other'})\n",
    "\n",
    "census_1930_2 = pd.read_csv('data/NHGIS/census_1930/nhgis0001_ds60_1930_tract.csv',index_col=None, header=0)\n",
    "census_1930_2 = census_1930_2.rename(columns={'BJW001':'population',\n",
    "                                          'BK1001':'white_native',\n",
    "                                          'BK1002':'white_foreignparents',\n",
    "                                          'BK1003':'white_foreign',\n",
    "                                          'BK1004':'colored',\n",
    "                                          'BK1005':'other' })\n",
    "\n",
    "census_1930_3 = pd.read_csv('data/NHGIS/census_1930/nhgis0001_ds62_1930_tract.csv',index_col=None, header=0)\n",
    "census_1930_3 = census_1930_3.rename(columns={'BLO001':'population',\n",
    "                                          'BLR001':'white_native',\n",
    "                                          'BLR002':'white_foreignparents',\n",
    "                                          'BLR003':'white_foreign',\n",
    "                                          'BLR004':'colored',\n",
    "                                        'BLR005':'other'})\n",
    "\n",
    "census_1930_4 = pd.read_csv('data/NHGIS/census_1930/nhgis0001_ds63_1930_tract.csv',index_col=None, header=0)\n",
    "census_1930_4 = census_1930_4.rename(columns={'BLW001':'population',\n",
    "                                           'BM4001':'white_native',\n",
    "                                          'BM4002':'white_foreignparents',\n",
    "                                          'BM4003':'white_foreign',\n",
    "                                          'BM4004':'colored',\n",
    "                                        'BM4005':'other'})\n",
    "\n",
    "census_1930_5 = pd.read_csv('data/NHGIS/census_1930/nhgis0001_ds64_1930_tract.csv',index_col=None, header=0)\n",
    "census_1930_5 = census_1930_5.rename(columns={'BND001':'population'})\n",
    "\n",
    "census_1930_6 = pd.read_csv('data/NHGIS/census_1930/nhgis0001_ds65_1930_tract.csv',index_col=None, header=0)\n",
    "census_1930_6 = census_1930_6.rename(columns={'BNE001':'population',\n",
    "                                          'BNP001':'white_native',\n",
    "                                          'BNP002':'white_foreignparents',\n",
    "                                          'BNP003':'white_foreign',\n",
    "                                          'BNP004':'colored',\n",
    "                                        'BNP005':'other'})\n",
    "\n",
    "census_1930_7 = pd.read_csv('data/NHGIS/census_1930/nhgis0001_ds66_1930_tract.csv',index_col=None, header=0)\n",
    "census_1930_7 = census_1930_7.rename(columns={'BOI001':'population'})\n",
    "\n",
    "census_1930_8 = pd.read_csv('data/NHGIS/census_1930/nhgis0001_ds67_1930_tract.csv',index_col=None, header=0)\n",
    "census_1930_8 = census_1930_8.rename(columns={'BOJ001':'population',\n",
    "                                          'BOK001':'white_native',\n",
    "                                          'BOK002':'white_foreignparents',\n",
    "                                          'BOK003':'white_foreign',\n",
    "                                          'BOK004':'colored',\n",
    "                                        'BOK005':'other'})\n",
    "\n",
    "census_1930_9 = pd.read_csv('data/NHGIS/census_1930/nhgis0001_ds68_1930_tract.csv',index_col=None, header=0)\n",
    "census_1930_9 = census_1930_9.rename(columns={'BOO001':'population',\n",
    "                                          'BPW001':'white_native',\n",
    "                                          'BPW002':'white_foreignparents',\n",
    "                                          'BPW003':'white_foreign',\n",
    "                                          'BPW004':'colored',\n",
    "                                        'BPW005':'other'})\n",
    "\n",
    "census_1930_10 = pd.read_csv('data/NHGIS/census_1930/nhgis0001_ds69_1930_tract.csv',index_col=None, header=0)\n",
    "census_1930_10 = census_1930_10.rename(columns={'BQM001':'population'})\n",
    "\n",
    "census_1930_11 = pd.read_csv('data/NHGIS/census_1930/nhgis0001_ds70_1930_tract.csv',index_col=None, header=0)\n",
    "census_1930_11 = census_1930_11.rename(columns={'BQQ001':'population',\n",
    "                                          'BRP001':'white_native',\n",
    "                                          'BRP002':'white_foreignparents',\n",
    "                                          'BRP003':'white_foreign',\n",
    "                                          'BRP004':'colored',\n",
    "                                        'BRP005':'other'})\n",
    "\n",
    "census_1930_12 = pd.read_csv('data/NHGIS/census_1930/nhgis0001_ds71_1930_tract.csv',index_col=None, header=0)\n",
    "census_1930_12 = census_1930_12.rename(columns={'BRQ001':'population',\n",
    "                                          'BRT001':'white_native',\n",
    "                                          'BRT002':'white_foreignparents',\n",
    "                                          'BRT003':'white_foreign',\n",
    "                                          'BRT004':'colored',\n",
    "                                        'BRT005':'other'})\n",
    "census_1930_13 = pd.read_csv('data/NHGIS/census_1930/nhgis0001_ds59_1930_tract.csv',index_col=None, header=0)\n",
    "census_1930_13 = census_1930_13.rename(columns={'BI1001':'population',\n",
    "                                          'BJR001':'white_native',\n",
    "                                          'BJR002':'white_foreign',\n",
    "                                          'BJR003':'colored'}) ### no other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate all the cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1930 = pd.concat([census_1930_1,census_1930_2,census_1930_3,census_1930_4,census_1930_5,\n",
    "                       census_1930_6,census_1930_7,census_1930_8,census_1930_9,census_1930_10,\n",
    "                       census_1930_11,census_1930_12,census_1930_13])\n",
    "#### Cleanup\n",
    "census_1930 = census_1930.drop_duplicates()\n",
    "census_1930 = census_1930.fillna(0)\n",
    "\n",
    "census_1930=census_1930[census_1930.population>0]\n",
    "census_1930=census_1930.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1930['white']=census_1930['white_foreign']\\\n",
    "                        +census_1930['white_foreignparents']\\\n",
    "                        +census_1930['white_native']\n",
    "        \n",
    "census_1930['white_perc']=census_1930['white']/census_1930['population']\n",
    "census_1930['colored_perc']=census_1930['colored']/census_1930['population']\n",
    "census_1930['other_perc']=census_1930['other']/census_1930['population']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1930.to_sql('census_1930', engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1940\n",
    "Using census from that year. Has the following columns: \n",
    "- Population\n",
    "- Race by white, colored, other\n",
    "- College education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1940 = pd.read_csv('data/NHGIS/census_1940/nhgis0003_ds76_1940_tract.csv',index_col=None, header=0)\n",
    "census_1940 = census_1940.rename(columns={'BUB001':'population',\n",
    "                                          'BUQ001':'white',\n",
    "                                          'BUQ002':'colored',\n",
    "                                          'BUH007':'college_male_1_3',\n",
    "                                          'BUH016':'college_female_1_3',\n",
    "                                          'BUH008':'college_male_4',\n",
    "                                          'BUH017':'college_female_4',\n",
    "                                         'GISJOIN':'gisjoin'})\n",
    "census_1940['college'] = census_1940['college_male_1_3']+census_1940['college_female_1_3']\\\n",
    "                        +census_1940['college_male_4']+census_1940['college_female_4']\n",
    "census_1940 = census_1940.drop_duplicates()\n",
    "census_1940 = census_1940.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1940['white_perc']=census_1940['white']/census_1940['population']\n",
    "census_1940['colored_perc']=census_1940['colored']/census_1940['population']\n",
    "\n",
    "### No \"other\" category\n",
    "census_1940['college_perc'] = (census_1940['college'])/ census_1940['population']\n",
    "\n",
    "#### Cleanup\n",
    "census_1940=census_1940[census_1940.population>0]\n",
    "census_1940=census_1940.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1940.to_sql('census_1940', engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1950\n",
    "Using census from that year. Has the following columns: \n",
    "- Population\n",
    "- Race by white, colored, other\n",
    "- College education, \n",
    "- Median income\n",
    "- Median value of home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1950 = pd.read_csv('data/NHGIS/census_1950/nhgis0021_ds82_1950_tract.csv',index_col=None, header=0)\n",
    "census_1950 = census_1950.rename(columns={'BZ8001':'population',\n",
    "                                          'B0J001':'white',\n",
    "                                          'B0J002':'colored',\n",
    "                                          'B0J003':'other',\n",
    "                                          'B0B008':'college_1_3',\n",
    "                                          'B0B009':'college_4',\n",
    "                                          'B0F001':'median_income',\n",
    "                                         'GISJOIN':'gisjoin'})\n",
    "census_1950['college'] = census_1950['college_1_3']+census_1950['college_4']\n",
    "\n",
    "### Adjust for inflation from 1949\n",
    "### from: http://www.in2013dollars.com/1949-dollars-in-2016\n",
    "infl_factor_1950= 10.08433\n",
    "census_1950['median_income_adj'] = infl_factor_1950*census_1950['median_income']\n",
    "census_1950 = census_1950.drop_duplicates()\n",
    "census_1950 = census_1950.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1950['white_perc']=census_1950['white']/(census_1950['white']+census_1950['colored']+census_1950['other'])\n",
    "census_1950['colored_perc']=census_1950['colored']/(census_1950['white']+census_1950['colored']+census_1950['other'])\n",
    "census_1950['other_perc']=census_1950['other']/(census_1950['white']+census_1950['colored']+census_1950['other'])\n",
    "\n",
    "census_1950['college_perc'] = (census_1950['college'] )/ census_1950['population']\n",
    "\n",
    "### Adjust for inflation from 1949\n",
    "### from: http://www.in2013dollars.com/1949-dollars-in-2016\n",
    "infl_factor_1950= 10.08433\n",
    "census_1950['median_income_adj']= infl_factor_1950*census_1950['median_income'].astype(float)\n",
    "\n",
    "#### Cleanup\n",
    "census_1950=census_1950[census_1950.population>0]\n",
    "census_1950=census_1950[(census_1950['white']+census_1950['colored']+census_1950['other'])>0]\n",
    "census_1950=census_1950.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28250.96270985663"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_1950['median_income_adj'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1950.to_sql('census_1950', engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1960\n",
    "Using census from that year. Has the following columns: \n",
    "- Population\n",
    "- Race by white, colored, other\n",
    "- Education\n",
    "- Income broken down by bins\n",
    "\n",
    "For 1960, since there are only median income clases, we find the median income by simulating incomes based on income ranges and getting the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenfeixu/anaconda2/envs/geo_wenfei/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/wenfeixu/anaconda2/envs/geo_wenfei/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "census_1960 = pd.read_csv('data/NHGIS/census_1960/nhgis0021_ds92_1960_tract.csv',index_col=None, header=0)\n",
    "census_1960 = census_1960.rename(columns={'CA4001':'population',\n",
    "                                          'B7B001':'white',\n",
    "                                          'B7B002':'colored',\n",
    "                                          'B7B003':'other',\n",
    "                                          'CA7001':'spanish_origin',\n",
    "                                          'B8R007':'college_1_3',\n",
    "                                          'B8R008':'college_4',\n",
    "                                          'B8W001':'less_1000',\n",
    "                                          'B8W002':'1000_1999',\n",
    "                                          'B8W003':'2000_2999',\n",
    "                                          'B8W004':'3000_3999',\n",
    "                                          'B8W005':'4000_4999',\n",
    "                                          'B8W006':'5000_5999',\n",
    "                                          'B8W007':'6000_6999',\n",
    "                                          'B8W008':'7000_7999',\n",
    "                                          'B8W009':'8000_8999',\n",
    "                                          'B8W010':'9000_9999',\n",
    "                                          'B8W011':'10000_14999',\n",
    "                                          'B8W012':'15000_24999',\n",
    "                                          'B8W013':'25000_over',\n",
    "                                         'GISJOIN':'gisjoin'})\n",
    "census_1960['hispanic']=census_1960['spanish_origin']\n",
    "census_1960['college']=(census_1960['college_1_3']+ census_1960['college_4'] )\n",
    "\n",
    "### Since median income is measured by households instead of population, recreate a households category\n",
    "census_1960['households']=(census_1960['less_1000']+census_1960['1000_1999']+census_1960['2000_2999']\\\n",
    "+census_1960['3000_3999']+census_1960['4000_4999'] +census_1960['5000_5999']\\\n",
    "+census_1960['6000_6999']+census_1960['7000_7999']+census_1960['8000_8999']\\\n",
    "+census_1960['9000_9999'] +census_1960['10000_14999']+census_1960['15000_24999']\\\n",
    "+census_1960['25000_over'])\n",
    "\n",
    "census_1960 = census_1960.drop_duplicates()\n",
    "census_1960 = census_1960.fillna(0)\n",
    "\n",
    "### Adjust for inflation in 1959\n",
    "### from: http://www.in2013dollars.com/1960-dollars-in-2016\n",
    "infl_factor_1960=8.24766\n",
    "\n",
    "census_1960['median_income']=census_1960.apply(lambda x:np.median(np.sort(np.concatenate([np.random.randint(0,999, size=int(x['less_1000'])),\n",
    "        np.random.randint(1000,1999, size=int(x['1000_1999'])),\n",
    "        np.random.randint(2000,2999, size=int(x['2000_2999'])),\n",
    "        np.random.randint(3000,3999, size=int(x['3000_3999'])),\n",
    "        np.random.randint(4000,4999, size=int(x['4000_4999'])),\n",
    "        np.random.randint(5000,5999, size=int(x['5000_5999'])),\n",
    "        np.random.randint(6000,6999, size=int(x['6000_6999'])),\n",
    "        np.random.randint(7000,7999, size=int(x['7000_7999'])),\n",
    "        np.random.randint(8000,8999, size=int(x['8000_8999'])),\n",
    "        np.random.randint(9000,9999, size=int(x['9000_9999'])),\n",
    "        np.random.randint(10000,14999, size=int(x['10000_14999'])),\n",
    "        np.random.randint(15000,24999, size=int(x['15000_24999'])),\n",
    "                                                             np.random.randint(25000,50000, size=int(x['25000_over']))\n",
    "                                                            ]))),axis=1)\n",
    "\n",
    "\n",
    "census_1960['median_income_adj']= infl_factor_1960*census_1960['median_income']\n",
    "# census_1960['median_income_adj']= infl_factor_1960*(census_1960['less_1000']*300\n",
    "#                                                    +census_1960['1000_1999']*1500\n",
    "#                                                    +census_1960['2000_2999']*2500\n",
    "#                                                    +census_1960['3000_3999']*3500\n",
    "#                                                    +census_1960['4000_4999']*4500\n",
    "#                                                    +census_1960['5000_5999']*5500\n",
    "#                                                    +census_1960['6000_6999']*6500\n",
    "#                                                    +census_1960['7000_7999']*7500\n",
    "#                                                    +census_1960['8000_8999']*8500\n",
    "#                                                    +census_1960['9000_9999']*9500\n",
    "#                                                    +census_1960['10000_14999']*12500\n",
    "#                                                    +census_1960['15000_24999']*20000\n",
    "#                                                    +census_1960['25000_over']*25000\n",
    "#                                                   )/census_1960['households']\n",
    "\n",
    "\n",
    "census_1960 = census_1960.drop_duplicates()\n",
    "census_1960 = census_1960.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51312.81669"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_1960['median_income_adj'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Population and race population don't add up\n",
    "census_1960['white_perc']=census_1960['white']/(census_1960['white']+census_1960['colored']+census_1960['other'])\n",
    "\n",
    "census_1960['colored_perc']=census_1960['colored']/(census_1960['white']+census_1960['colored']+census_1960['other'])\n",
    "census_1960['hispanic_perc']=census_1960['spanish_origin']/(census_1960['population'])\n",
    "census_1960['other_perc']=census_1960['other']/(census_1960['white']+census_1960['colored']+census_1960['other'])\n",
    "\n",
    "census_1960['college_perc'] = (census_1960['college'] )/ census_1960['population']\n",
    "\n",
    "#### Cleanup\n",
    "census_1960=census_1960[census_1960.population>0]\n",
    "census_1960=census_1960[(census_1960['white']+census_1960['colored']+census_1960['other'])>0]\n",
    "census_1960=census_1960.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1960.to_sql('census_1960', engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1970\n",
    "Using census from that year. Has the following columns: \n",
    "- Population\n",
    "- Race by white, colored, other\n",
    "- Education\n",
    "- Median Income\n",
    "- Employment Status\n",
    "\n",
    "For 1970, since the aggregate median incomes don't look correct. We use the median income clases and find the median income by simulating incomes based on income ranges and getting the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenfeixu/anaconda2/envs/geo_wenfei/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/wenfeixu/anaconda2/envs/geo_wenfei/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/wenfeixu/anaconda2/envs/geo_wenfei/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "census_1970_1 = pd.read_csv('data/NHGIS/census_1970/nhgis0027_ds98_1970_tract.csv',index_col=None, header=0)\n",
    "census_1970_2 = pd.read_csv('data/NHGIS/census_1970/nhgis0027_ds99_1970_tract.csv',index_col=None, header=0)\n",
    "census_1970_3 = pd.read_csv('data/NHGIS/census_1970/nhgis0027_ds95_1970_tract.csv',index_col=None, header=0)\n",
    "census_1970_4 = pd.read_csv('data/NHGIS/census_1970/nhgis0027_ds97_1970_tract.csv',index_col=None, header=0)\n",
    "census_1970_5 = pd.read_csv('data/NHGIS/census_1970/nhgis0029_ds99_1970_tract.csv',index_col=None, header=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "census_1970_1 = census_1970_1.rename(columns={'C1I001':'population',\n",
    "                                          'C0X001':'white',\n",
    "                                          'C0X002':'colored',\n",
    "                                          'C0X003':'other',\n",
    "                                          'C06008':'college_1_3',\n",
    "                                          'C06009':'college_4',\n",
    "                                          'C06010':'college_5_more',\n",
    "                                          'C07003':'unemployed',\n",
    "                                         'GISJOIN':'gisjoin'})\n",
    "\n",
    "census_1970_2 = census_1970_2.rename(columns={\n",
    "                                          'C3T001':'less_1000',\n",
    "                                          'C3T002':'1000_1999',\n",
    "                                          'C3T003':'2000_2999',\n",
    "                                          'C3T004':'3000_3999',\n",
    "                                          'C3T005':'4000_4999',\n",
    "                                          'C3T006':'5000_5999',\n",
    "                                          'C3T007':'6000_6999',\n",
    "                                          'C3T008':'7000_7999',\n",
    "                                          'C3T009':'8000_8999',\n",
    "                                          'C3T010':'9000_9999',\n",
    "                                          'C3T011':'10000_11999',\n",
    "                                          'C3T012':'12000_14999',\n",
    "                                          'C3T013':'15000_24999',\n",
    "                                          'C3T014':'25000_49999',\n",
    "                                          'C3T015':'50000_over',\n",
    "                                            'GISJOIN':'gisjoin'})\n",
    "\n",
    "# census_1970_2['households']=(census_1970_2['less_1000']+census_1970_2['1000_1999']+census_1970_2['2000_2999']\\\n",
    "# +census_1970_2['3000_3999']+census_1970_2['4000_4999'] +census_1970_2['5000_5999']\\\n",
    "# +census_1970_2['6000_6999']+census_1970_2['7000_7999']+census_1970_2['8000_8999']\\\n",
    "# +census_1970_2['9000_9999'] +census_1970_2['10000_11999']+census_1970_2['12000_14999']+census_1970_2['15000_24999']\\\n",
    "# +census_1970_2['25000_49999']+census_1970_2['50000_over'])\n",
    "\n",
    "census_1970_2 = census_1970_2.fillna(0)\n",
    "census_1970_2 = census_1970_2.replace(-1,0)\n",
    "\n",
    "# census_1970_2['median_income'] = census_1970_2.apply(lambda x: np.median(np.concatenate([np.repeat(300,x['less_1000']),np.repeat(1500,x['1000_1999']),\n",
    "#                np.repeat(2500,x['2000_2999']),np.repeat(3500,x['3000_3999']),\n",
    "#                np.repeat(4500,x['4000_4999']),np.repeat(5500,x['5000_5999']),\n",
    "#                np.repeat(6500,x['6000_6999']),np.repeat(7500,x['7000_7999']),\n",
    "#                 np.repeat(8500,x['8000_8999']),np.repeat(9500,x['9000_9999']),\n",
    "#                 np.repeat(11000,x['10000_11999']),\n",
    "#                np.repeat(1350,x['12000_14999']),np.repeat(20000,x['15000_24999']),\n",
    "#                 np.repeat(37500,x['25000_49999']),np.repeat(50000,x['50000_over'])])),axis=1)\n",
    "census_1970_2['median_income']=census_1970_2.apply(lambda x:np.median(np.sort(np.concatenate([np.random.randint(0,999, size=int(x['less_1000'])),\n",
    "        np.random.randint(1000,1999, size=int(x['1000_1999'])),\n",
    "        np.random.randint(2000,2999, size=int(x['2000_2999'])),\n",
    "        np.random.randint(3000,3999, size=int(x['3000_3999'])),\n",
    "        np.random.randint(4000,4999, size=int(x['4000_4999'])),\n",
    "        np.random.randint(5000,5999, size=int(x['5000_5999'])),\n",
    "        np.random.randint(6000,6999, size=int(x['6000_6999'])),\n",
    "        np.random.randint(7000,7999, size=int(x['7000_7999'])),\n",
    "        np.random.randint(8000,8999, size=int(x['8000_8999'])),\n",
    "        np.random.randint(9000,9999, size=int(x['9000_9999'])),\n",
    "        np.random.randint(10000,11999, size=int(x['10000_11999'])),\n",
    "        np.random.randint(12000,14999, size=int(x['12000_14999'])),\n",
    "        np.random.randint(15000,24999, size=int(x['15000_24999'])),\n",
    "        np.random.randint(25000,49999, size=int(x['25000_49999'])),\n",
    "        np.random.randint(50000,80000, size=int(x['50000_over']))\n",
    "                                                            ]))),axis=1)\n",
    "\n",
    "\n",
    "census_1970_3 = census_1970_3.rename(columns={'CEB003':'indian_m',\n",
    "                                          'CEB004':'japanese_m',\n",
    "                                          'CEB005':'chinese_m',\n",
    "                                          'CEB006':'filipino_m',\n",
    "                                          'CEB007':'hawaiian_m',\n",
    "                                          'CEB008':'korean_m',\n",
    "                                          'CEB012':'indian_f',\n",
    "                                          'CEB013':'japanese_f',\n",
    "                                          'CEB014':'chinese_f',\n",
    "                                          'CEB015':'filipino_f',\n",
    "                                          'CEB016':'hawaiian_f',\n",
    "                                          'CEB017':'korean_f',\n",
    "                                         'GISJOIN':'gisjoin'})\n",
    "\n",
    "census_1970_3['asian']=census_1970_3['indian_m']+census_1970_3['japanese_m']+\\\n",
    "                                          census_1970_3['chinese_m']+\\\n",
    "                                          census_1970_3['filipino_m']+\\\n",
    "                                          census_1970_3['hawaiian_m']+\\\n",
    "                                          census_1970_3['korean_m']+\\\n",
    "                                          census_1970_3['indian_f']+\\\n",
    "                                          census_1970_3['japanese_f']+\\\n",
    "                                          census_1970_3['chinese_f']+\\\n",
    "                                          census_1970_3['filipino_f']+\\\n",
    "                                          census_1970_3['hawaiian_f']+\\\n",
    "                                          census_1970_3['korean_f']\n",
    "census_1970_4 = census_1970_4.rename(columns={\n",
    "                                          'CY9001':'spanish_origin',\n",
    "                                            'GISJOIN':'gisjoin'})\n",
    "census_1970_5 = census_1970_5.rename(columns={\n",
    "                                          'C1K001':'median_income_agg',\n",
    "                                            'GISJOIN':'gisjoin'})\n",
    "\n",
    "\n",
    "census_1970 =census_1970_1.set_index('gisjoin')\\\n",
    "                        .join(census_1970_2[['gisjoin','median_income']].set_index('gisjoin'))\\\n",
    "                        .join(census_1970_3[['gisjoin','asian']].set_index('gisjoin'))\\\n",
    "                        .join(census_1970_4[['gisjoin','spanish_origin']].set_index('gisjoin'))\\\n",
    "                        .join(census_1970_5[['gisjoin','median_income_agg']].set_index('gisjoin')).reset_index()\n",
    "\n",
    "            \n",
    "census_1970['hispanic']=census_1970['spanish_origin']\n",
    "census_1970['college']=census_1970['college_1_3']+census_1970['college_4']+census_1970['college_5_more']\n",
    "\n",
    "### Adjust for inflation in 1969\n",
    "### from: http://www.in2013dollars.com/1969-dollars-in-2016\n",
    "infl_factor_1970=6.53970\n",
    "# census_1970['households']=(census_1970_2['less_1000']+census_1970_2['1000_1999']+census_1970['2000_2999']\\\n",
    "# +census_1970['3000_3999']+census_1970['4000_4999'] +census_1970['5000_5999']\\\n",
    "# +census_1970['6000_6999']+census_1970['7000_7999']+census_1970['8000_8999']\\\n",
    "# +census_1970['9000_9999'] +census_1970['10000_11999']+census_1970['12000_14999']+census_1970['15000_24999']\\\n",
    "# +census_1970['25000_49999']+census_1970['50000_over'])\n",
    "\n",
    "\n",
    "census_1970['median_income_adj']= infl_factor_1970*census_1970['median_income']\n",
    "\n",
    "# census_1970['median_income_adj']= infl_factor_1970*(census_1970['less_1000']*300\n",
    "#                                                    +census_1970['1000_1999']*1500\n",
    "#                                                    +census_1970['2000_2999']*2500\n",
    "#                                                    +census_1970['3000_3999']*3500\n",
    "#                                                    +census_1970['4000_4999']*4500\n",
    "#                                                    +census_1970['5000_5999']*5500\n",
    "#                                                    +census_1970['6000_6999']*6500\n",
    "#                                                    +census_1970['7000_7999']*7500\n",
    "#                                                    +census_1970['8000_8999']*8500\n",
    "#                                                    +census_1970['9000_9999']*9500\n",
    "#                                                    +census_1970['10000_11999']*11000\n",
    "#                                                    +census_1970['12000_14999']*13500\n",
    "#                                                    +census_1970['15000_24999']*20000\n",
    "#                                                    +census_1970['25000_49999']*37500\n",
    "#                                                    +census_1970['50000_over']*50000\n",
    "#                                                   )/census_1970['households']\n",
    "\n",
    "\n",
    "\n",
    "#### Cleanup\n",
    "census_1970 = census_1970.drop_duplicates()\n",
    "census_1970 = census_1970.fillna(0)\n",
    "census_1970=census_1970[census_1970.population>0]\n",
    "census_1970=census_1970[(census_1970['white']+census_1970['colored']+census_1970['other'])>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66005.1921"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_1970['median_income_adj'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using the sume of races here becaucse I think population was a little wonky? \n",
    "census_1970['white_perc']=census_1970['white']/(census_1970['white']+census_1970['colored']+census_1970['other'])\n",
    "census_1970['asian_perc']=census_1970['asian']/(census_1970['white']+census_1970['colored']+census_1970['other'])\n",
    "                                              \n",
    "census_1970['colored_perc'] = census_1970['colored']/(census_1970['white']+census_1970['colored']+census_1970['other'])\n",
    "\n",
    "census_1970['hispanic_perc']=census_1970['hispanic']/(census_1970['white']+census_1970['colored']+census_1970['other'])\n",
    "census_1970['other_perc']=census_1970['other']/(census_1970['white']+census_1970['colored']+census_1970['other'])\n",
    "census_1970['college_perc'] = (census_1970['college'] )/ (census_1970['white']+census_1970['colored']+census_1970['other'])\n",
    "census_1970['unemployed_perc'] = (census_1970['unemployed'] )/ (census_1970['white']+census_1970['colored']+census_1970['other'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1970.to_sql('census_1970', engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1980\n",
    "Using census from that year. Has the following columns: \n",
    "- Population\n",
    "- Race by white, colored, other types of asian\n",
    "- Education\n",
    "- Median Income\n",
    "- Employment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1980_1 = pd.read_csv('data/NHGIS/census_1980/nhgis0027_ds104_1980_tract.csv',index_col=None, header=0)\n",
    "census_1980_2 = pd.read_csv('data/NHGIS/census_1980/nhgis0027_ds107_1980_tract.csv',index_col=None, header=0)\n",
    "\n",
    "\n",
    "\n",
    "census_1980_1 = census_1980_1.rename(columns={'C7L001':'population',\n",
    "                                          'C9D001':'white',\n",
    "                                          'C9D002':'colored',\n",
    "                                          'C9D003':'american_indian',\n",
    "                                          'C9D004':'eskimo',\n",
    "                                          'C9D005':'aleut',\n",
    "                                          'C9D006':'japanese',\n",
    "                                          'C9D007':'chinese',\n",
    "                                          'C9D008':'filipino',\n",
    "                                          'C9D009':'korean',\n",
    "                                          'C9D010':'asian_indian',\n",
    "                                          'C9D011':'vietnamese',\n",
    "                                          'C9D012':'hawaiian',\n",
    "                                          'C9D013':'guamian',\n",
    "                                          'C9D014':'samoan',\n",
    "                                          'C9D015':'other',\n",
    "                                          'C9E001':\"non_spanish\",\n",
    "                                          'C9E002':'mexican',\n",
    "                                           'C9E003':'puerto_rican',\n",
    "                                              'C9E004':'cuban',\n",
    "                                              'C9E005':'other_spanish',\n",
    "                                          'GISJOIN':'gisjoin'})\n",
    "census_1980_2 = census_1980_2.rename(columns={'DHM004':'college_1_3',\n",
    "                                              'DHM005':'college_4',\n",
    "                                              'DHX003':'unemployed_male',\n",
    "                                              'DHX007':'unemployed_female',\n",
    "                                              'DIE001':'median_income',\n",
    "                                         'GISJOIN':'gisjoin'})\n",
    "\n",
    "census_1980 =census_1980_1.set_index('gisjoin').join(census_1980_2[['gisjoin',\n",
    "                                                                    'college_1_3',\n",
    "                                                                    'college_4',\n",
    "                                                                    'unemployed_male',\n",
    "                                                                    'unemployed_female',\n",
    "                                                                    'median_income']].set_index('gisjoin')).reset_index()\n",
    "census_1980['other']=(census_1980['american_indian']+census_1980['eskimo']+census_1980['aleut']+census_1980['japanese']+\\\n",
    "                    census_1980['chinese']+census_1980['filipino']+census_1980['korean']+census_1980['asian_indian']+\\\n",
    "                    census_1980['vietnamese']+census_1980['hawaiian']+census_1980['guamian']+census_1980['samoan']+census_1980['other'])\n",
    "\n",
    "census_1980['hispanic']= (census_1980['mexican']+census_1980['puerto_rican']+census_1980['cuban']+census_1980['other_spanish'])\n",
    "census_1980['college'] =census_1980['college_1_3']+census_1980['college_4']\n",
    "census_1980['unemployed'] =census_1980['unemployed_male']+census_1980['unemployed_female']\n",
    "\n",
    "### Adjust for inflation in 1979\n",
    "### from: http://www.in2013dollars.com/1950-dollars-in-2016\n",
    "infl_factor_1980=3.30588\n",
    "census_1980['median_income_adj']= infl_factor_1980*(census_1980['median_income']).astype(float)\n",
    "\n",
    "#### Cleanup\n",
    "census_1980=census_1980[census_1980.population>0]\n",
    "census_1980 = census_1980.drop_duplicates()\n",
    "census_1980 = census_1980.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1980['white_perc']=census_1980['white']/census_1980['population']\n",
    "census_1980['colored_perc']=census_1980['colored']/census_1980['population']\n",
    "census_1980['hispanic_perc'] = (census_1980['hispanic'])/(census_1980['population'])\n",
    "census_1980['other_perc']=(census_1980['other']) /census_1980['population']\n",
    "census_1980['college_perc'] = (census_1980['college'] )/ census_1980['population']\n",
    "census_1980['unemployed_perc'] = (census_1980['unemployed'] )/ census_1980['population']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1980.to_sql('census_1980', engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting 1990 we use block groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1990\n",
    "\n",
    "Using census from that year. Has the following columns: \n",
    "- Population\n",
    "- Race by white, colored, other\n",
    "- Education\n",
    "- Median Income\n",
    "- Employment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenfeixu/anaconda2/envs/geo_wenfei/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (16,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/wenfeixu/anaconda2/envs/geo_wenfei/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (15,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'holc_tract_1990' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0717a77cfaf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m#### Cleanup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mholc_tract_1990\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mholc_tract_1990\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mholc_tract_1990\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mcensus_1990\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcensus_1990\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mcensus_1990\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcensus_1990\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'holc_tract_1990' is not defined"
     ]
    }
   ],
   "source": [
    "census_1990_1 = pd.read_csv('data/NHGIS/census_1990/nhgis0023_ds120_1990_blck_grp.csv',index_col=None, header=0)\n",
    "census_1990_2 = pd.read_csv('data/NHGIS/census_1990/nhgis0023_ds123_1990_blck_grp.csv',index_col=None, header=0)\n",
    "census_1990_1['PMSAA']=census_1990_1['PMSAA'].astype(str)\n",
    "census_1990_1['MSA_CMSAA']=census_1990_1['MSA_CMSAA'].astype(str)\n",
    "census_1990_2['PMSAA']=census_1990_2['PMSAA'].astype(str)\n",
    "census_1990_2['MSA_CMSAA']=census_1990_2['MSA_CMSAA'].astype(str)\n",
    "\n",
    "census_1990_1 = census_1990_1.rename(columns={'ET1001':'population',\n",
    "                                          'ET2001':'white',\n",
    "                                          'ET2002':'colored',\n",
    "                                          'ET2003':'native_american',\n",
    "                                          'ET2004':'asian',\n",
    "                                          'ET2005':'other',\n",
    "                                          'ET2006':'white_hispanic',\n",
    "                                          'ET2007':'black_hispanic',\n",
    "                                          'ET2008':'indian_hispanic',\n",
    "                                          'ET2009':'asian_hispanic',\n",
    "                                          'ET2010':'other_hispanic',\n",
    "                                          'EST001':'median_value',\n",
    "                                          'GISJOIN':'gisjoin'})\n",
    "census_1990_1['hispanic']=census_1990_1['white_hispanic']+census_1990_1['black_hispanic']\\\n",
    "                            +census_1990_1['indian_hispanic']+census_1990_1['asian_hispanic']+census_1990_1['other_hispanic']\n",
    "census_1990_1['other']=census_1990_1['other']+census_1990_1['asian']+census_1990_1['native_american']\n",
    "census_1990_2 = census_1990_2.rename(columns={'E33004':'college_notcomplete',\n",
    "                                              'E33005':'college_1_3',\n",
    "                                              'E33006':'college_4',\n",
    "                                              'E33007':'graduate',\n",
    "                                              'E4I003':'unemployed_male',\n",
    "                                              'E4I007':'unemployed_female',\n",
    "                                              'E4U001':'median_income',\n",
    "                                         'GISJOIN':'gisjoin'})\n",
    "census_1990_2['college']=census_1990_2['college_notcomplete']+census_1990_2['college_1_3']\\\n",
    "                            + census_1990_2['college_4']+census_1990_2['graduate']\n",
    "census_1990_2['unemployed']=census_1990_2['unemployed_female']+census_1990_2['unemployed_male']\n",
    "\n",
    "### Adjust for inflation in 1989\n",
    "### from: http://www.in2013dollars.com/1950-dollars-in-2016\n",
    "infl_factor_1990=1.93554\n",
    "census_1990_2['median_income_adj']= infl_factor_1990*(census_1990_2['median_income']).astype(float)\n",
    "\n",
    "census_1990 =census_1990_1.set_index('gisjoin').join(census_1990_2[['gisjoin',\n",
    "                                                                    \"college\",\n",
    "                                                                    'unemployed',\n",
    "                                                                    'median_income_adj',\n",
    "                                                                    'median_income']].set_index('gisjoin')).reset_index()\n",
    "\n",
    "#### Cleanup \n",
    "holc_tract_1990=holc_tract_1990[holc_tract_1990.population>0]\n",
    "census_1990 = census_1990.drop_duplicates()\n",
    "census_1990 = census_1990.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census_1990[census_1990['unemployed_perc']>1][['unemployed','population']]\n",
    "# [['college_perc','college','population']].sort_values('college_perc',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1990['white_perc']=census_1990['white']/census_1990['population']\n",
    "census_1990['colored_perc']=census_1990['colored']/census_1990['population']\n",
    "census_1990['other_perc']=(census_1990['other']) /census_1990['population']\n",
    "census_1990['hispanic_perc']=(census_1990['hispanic']) /census_1990['population']\n",
    "\n",
    "census_1990['college_perc'] = (census_1990['college'])/ census_1990['population']\n",
    "census_1990['unemployed_perc']= (census_1990['unemployed'])/census_1990['population'].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_1990.to_sql('census_1990', engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2000\n",
    "Using census from that year. Has the following columns: \n",
    "- Population\n",
    "- Race by white, colored, other\n",
    "- Education\n",
    "- Median Income\n",
    "- Employment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2000_1 = pd.read_csv('data/NHGIS/census_2000/nhgis0023_ds147_2000_blck_grp.csv',index_col=None, header=0)\n",
    "census_2000_2 = pd.read_csv('data/NHGIS/census_2000/nhgis0023_ds152_2000_blck_grp.csv',index_col=None, header=0)\n",
    "\n",
    "\n",
    "census_2000_1 = census_2000_1.rename(columns={'FXS001':'population',\n",
    "                                          'FYF001':'white',\n",
    "                                          'FYF002':'colored',\n",
    "                                          'FYF003':'native_american',\n",
    "                                          'FYF004':'asian',\n",
    "                                          'FYF005':'pacific_islander',\n",
    "                                          'FYF008':'white_hispanic',\n",
    "                                          'FYF009':'black_hispanic',\n",
    "                                          'FYF010':'indian_hispanic',\n",
    "                                          'FYF011':'asian_hispanic',\n",
    "                                          'FYF012':'islander_hispanic',\n",
    "                                          'FYF013':'other_hispanic',\n",
    "                                          'FYF014':'twoother_hispanic',\n",
    "                                          'FYE006':'one_other',\n",
    "                                          'FYE007':'two_other',\n",
    "                                          'GISJOIN':'gisjoin'})\n",
    "\n",
    "census_2000_1['hispanic']=census_2000_1['white_hispanic']+census_2000_1['black_hispanic']+\\\n",
    "                        census_2000_1['indian_hispanic']+census_2000_1['asian_hispanic']+\\\n",
    "                        census_2000_1['islander_hispanic']+census_2000_1['other_hispanic']+census_2000_1['twoother_hispanic']\n",
    "\n",
    "census_2000_1['other']=census_2000_1['native_american']+census_2000_1['asian']+census_2000_1['pacific_islander']+census_2000_1['one_other']+census_2000_1['two_other']\n",
    "\n",
    "\n",
    "census_2000_2 = census_2000_2.rename(columns={'HD1011':'somecollege_male',\n",
    "                                              'HD1012':'college_1_3_male',\n",
    "                                              'HD1013':'college_4_male',\n",
    "                                              'HD1014':'masters_male',\n",
    "                                              'HD1015':'professional_male',\n",
    "                                              'HD1016':'doctorate_male',\n",
    "                                              'HD1027':'somecollege_female',\n",
    "                                              'HD1028':'college_1_3_female',\n",
    "                                              'HD1029':'college_4_female',\n",
    "                                              'HD1030':'masters_female',\n",
    "                                              'HD1031':'professional_female',\n",
    "                                              'HD1032':'doctorate_female',\n",
    "                                              'HEZ002':'unemployed_male',\n",
    "                                              'HEZ004':'unemployed_female',\n",
    "                                              'HF6001':'median_income',\n",
    "                                         'GISJOIN':'gisjoin'})\n",
    "census_2000_2['college'] = census_2000_2['somecollege_male']+ census_2000_2['college_1_3_male']+census_2000_2['college_4_male']\\\n",
    "                            +census_2000_2['masters_male']+census_2000_2['professional_male']+census_2000_2['doctorate_male']\\\n",
    "                            +census_2000_2['somecollege_female']+ census_2000_2['college_1_3_female']+census_2000_2['college_4_female']\\\n",
    "                            +census_2000_2['masters_female']+census_2000_2['professional_female']+census_2000_2['doctorate_female']\\\n",
    "\n",
    "census_2000_2['unemployed']=census_2000_2['unemployed_male']+census_2000_2['unemployed_female']\n",
    "census_2000 =census_2000_1.set_index('gisjoin').join(census_2000_2[['gisjoin',\n",
    "                                             'college',\n",
    "                                              'unemployed',\n",
    "                                             'median_income']].set_index('gisjoin')).reset_index()\n",
    "\n",
    "### Adjust for inflation in 1999\n",
    "### from: http://www.in2013dollars.com/1950-dollars-in-2016\n",
    "infl_factor_2000=1.44062\n",
    "census_2000['median_income_adj']= infl_factor_2000*(census_2000['median_income']).astype(float)\n",
    "\n",
    "### Cleanup\n",
    "census_2000=census_2000[census_2000.population>0]\n",
    "census_2000 = census_2000.drop_duplicates()\n",
    "census_2000= census_2000.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44531.14644084084"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_2000['median_income'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2000['white_perc']=census_2000['white']/census_2000['population']\n",
    "census_2000['colored_perc']=census_2000['colored']/census_2000['population']\n",
    "census_2000['other_perc']=(census_2000['other']) /census_2000['population']\n",
    "census_2000['hispanic_perc']=(census_2000['hispanic']) /census_2000['population']\n",
    "\n",
    "census_2000['college_perc'] = (census_2000['college'] )/ census_2000['population']\n",
    "census_2000['unemployed_perc']= (census_2000['unemployed'])/census_2000['population'].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2000.to_sql('census_2000', engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2010\n",
    "**Starting 2010, longform census no longer exists - replaced with ACS data. **\n",
    "\n",
    "Using census from that year and 2008-2012 ACS. Has the following columns: \n",
    "- Population\n",
    "- Race by white, colored, other\n",
    "- Education\n",
    "- Median Income\n",
    "- Employment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Had to change encoding to 'latin-1'\n",
    "census_2010_1 = pd.read_csv('data/NHGIS/census_2010/nhgis0023_ds171_2010_blck_grp.csv',index_col=None, header=0,encoding='latin-1')\n",
    "census_2010_2 = pd.read_csv('data/NHGIS/census_2010/nhgis0023_ds172_2010_blck_grp.csv',index_col=None, header=0,encoding='latin-1')\n",
    "census_2010_3 = pd.read_csv('data/NHGIS/census_2010/nhgis0023_ds191_20125_2012_blck_grp.csv',index_col=None, header=0,encoding='latin-1')\n",
    "\n",
    "census_2010_1 = census_2010_1.rename(columns={\n",
    "                                            'H7R001':'population',\n",
    "                                            'H7R002':'hispanic',\n",
    "                                          'H7R005':'white',\n",
    "                                          'H7R006':'colored',\n",
    "                                          'H7R007':'native_american',\n",
    "                                          'H7R008':'asian',\n",
    "                                          'H7R009':'pacific_islander',\n",
    "                                          'H7R010':'one_other',\n",
    "                                          'H7R011':'two_other',\n",
    "                                            'H7R028':'three_other',\n",
    "                                          'H7R049':'four_other',\n",
    "                                            'H7R065':'five_other',\n",
    "                                            'H7R072':'six_other',\n",
    "                                          'GISJOIN':'gisjoin'})\n",
    "census_2010_1['other']=census_2010_1['native_american']+census_2010_1['asian']+\\\n",
    "                        census_2010_1['pacific_islander']+census_2010_1['one_other']+\\\n",
    "                        census_2010_1['two_other']+census_2010_1['three_other']+census_2010_1['four_other']+\\\n",
    "                        census_2010_1['five_other']+census_2010_1['six_other']\n",
    "# census_2010_2 = census_2010_2.rename(columns={\n",
    "#                                           'H7V001':'population',\n",
    "# #                                           'H7X002':'white',\n",
    "# #                                             'H7X003':'colored',\n",
    "# #                                             'H7X005':'asian',\n",
    "# #                                             'H7X006':'pacific_islander',\n",
    "# #                                             'H7X006':'one_other',\n",
    "# #                                             'H7X007':'two_other',\n",
    "#                                           'GISJOIN':'gisjoin'})\n",
    "\n",
    "census_2010_3 = census_2010_3.rename(columns={'QUSE020':'somecollege',\n",
    "                                              'QUSE021':'college_1_3',\n",
    "                                              'QUSE022':'college_4',\n",
    "                                              'QUSE023':'masters',\n",
    "                                              'QUSE024':'professional',\n",
    "                                              'QUSE025':'doctorate',\n",
    "                                              'QU1E001':'median_income',\n",
    "                                              'QXSE005':'unemployed',\n",
    "                                              'QUSE001':'edu_total',\n",
    "                                         'GISJOIN':'gisjoin'})\n",
    "census_2010_3['college'] =census_2010_3['somecollege'] +census_2010_3['college_1_3'] +census_2010_3['college_4']\\\n",
    "                        +census_2010_3['masters'] +census_2010_3['professional'] +census_2010_3['doctorate']\n",
    "census_2010 =census_2010_1[['population','white','colored','hispanic','other','gisjoin']].set_index('gisjoin').join(census_2010_3[['gisjoin',\n",
    "                                            'college','edu_total',\n",
    "                                            'unemployed',\n",
    "                                             'median_income']].set_index('gisjoin')).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "### Adjust for inflation in 2012, the values are in 2012 inflation adjusted dollars\n",
    "infl_factor_2012=1.04535\n",
    "census_2010['median_income_adj']= infl_factor_2012*(census_2010['median_income']).astype(float)\n",
    "\n",
    "### Cleanup\n",
    "census_2010=census_2010[census_2010.population>0]\n",
    "census_2010=census_2010.fillna(0)\n",
    "\n",
    "census_2010 = census_2010.drop_duplicates()\n",
    "census_2010 = census_2010.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2010['white_perc']=census_2010['white']/census_2010['population']\n",
    "census_2010['colored_perc']=census_2010['colored']/census_2010['population']\n",
    "census_2010['other_perc']=(census_2010['other']) /census_2010['population']\n",
    "census_2010['hispanic_perc']=(census_2010['hispanic']) /census_2010['population']\n",
    "census_2010['college_perc'] = (census_2010['college'])/ census_2010['edu_total']\n",
    "census_2010['unemployed_perc']= (census_2010['unemployed'])/census_2010['population'].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2010.to_sql('census_2010', engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016\n",
    "**2016 1yr ACS data. **\n",
    "\n",
    "Has the following columns: \n",
    "- Population\n",
    "- Race by white, colored, other\n",
    "- Education\n",
    "- Median Income\n",
    "- Employment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Had to change encoding to 'latin-1'\n",
    "census_2016 = pd.read_csv('data/NHGIS/census_2016/nhgis0024_ds225_20165_2016_blck_grp.csv',index_col=None, header=0,encoding='latin-1')\n",
    "\n",
    "census_2016 = census_2016.rename(columns={'AF2LE001':'population',\n",
    "                                          'AF2UE003':'white',\n",
    "                                          'AF2UE004':'colored',\n",
    "                                          'AF2UE005':'native_american',\n",
    "                                          'AF2UE006':'asian',\n",
    "                                          'AF2UE007':'pacific_islander',\n",
    "                                          'AF2ME007':'one_other',\n",
    "                                          'AF2ME008':'two_other',\n",
    "                                          'AF2UE013':'hispanic_white',\n",
    "                                          'AF2UE014':'hispanic_black',\n",
    "                                          'AF2UE015':'hispanic_indian',\n",
    "                                          'AF2UE016':'hispanic_asian',\n",
    "                                          'AF2UE017':'hispanic_islander',\n",
    "                                          'AF2UE018':'hispanic_other',\n",
    "                                          'AF2UE019':'hispanic_twoother',\n",
    "                                          'AF2UE020':'hispanic_twootherother',\n",
    "                                          'AF4OE020':'somecollege',\n",
    "                                              'AF4OE021':'college_1_3',\n",
    "                                              'AF4OE022':'college_4',\n",
    "                                              'AF4OE023':'masters',\n",
    "                                              'AF4OE024':'professional',\n",
    "                                              'AF4OE025':'doctorate',\n",
    "                                              'AF49E001':'median_income',\n",
    "                                              'AF67E005':'unemployed',\n",
    "                                              'AF9LE001':'median_value',\n",
    "                                         'GISJOIN':'gisjoin'})\n",
    "census_2016['hispanic']=census_2016['hispanic_white']+census_2016['hispanic_black']+census_2016['hispanic_indian']+census_2016['hispanic_asian']\\\n",
    "                        +census_2016['hispanic_islander']+census_2016['hispanic_other']+census_2016['hispanic_twoother']+census_2016['hispanic_twootherother']\n",
    "census_2016['other']=census_2016['native_american']+census_2016['asian']+census_2016['pacific_islander']+census_2016['one_other']+census_2016['two_other']\n",
    "census_2016['college']= census_2016['somecollege']+census_2016['college_1_3']+census_2016['college_4']+census_2016['masters']\\\n",
    "                        + census_2016['professional']+census_2016['doctorate']\n",
    "\n",
    "census_2016['median_income_adj']= (census_2016['median_income']).astype(float)\n",
    "\n",
    "### Cleanup\n",
    "census_2016=census_2016[census_2016.population>0]\n",
    "census_2016 = census_2016.drop_duplicates()\n",
    "census_2016 = census_2016.fillna(0)\n",
    "cols_keep = ['gisjoin','population','white','colored','other','native_american','asian','pacific_islander','hispanic','college','median_income_adj','unemployed']\n",
    "census_2016 = census_2016[cols_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2016['white_perc']=census_2016['white']/census_2016['population']\n",
    "census_2016['colored_perc']=census_2016['colored']/census_2016['population']\n",
    "census_2016['other_perc']=(census_2016['other']) /census_2016['population']\n",
    "census_2016['hispanic_perc']=(census_2016['hispanic']) /census_2016['population']\n",
    "census_2016['college_perc'] = (census_2016['college'])/ census_2016['population']\n",
    "census_2016['unemployed_perc']= (census_2016['unemployed'])/census_2016['population'].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2016.to_sql('census_2016', engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are some duplicates in the census data\n",
    "They look like this: \n",
    "```\n",
    "152\tTract   K0001     in Boston MA\t4258\t**1389**\t**1414**\t1200\tC\tBoston\t4806\t4003\t0.9401127289807421\t0.0577736026303429\t0.00211366838891498\tC\t0.233629061563406\t0.234096988926357\n",
    "\n",
    "233\tTract   K0001     in Boston MA\t4258\t**1388**\t**1413**\t1200\tC\tBoston\t4806\t4001\t0.9396430248943169\t0.0577736026303429\t0.00211366838891498\tC\t0.233629061563406\t0.234096988926357\n",
    "```\n",
    "We'll run for example:\n",
    "```\n",
    "select distinct on (\"AREANAME\")\n",
    "* from census_1930;\n",
    "```\n",
    "\n",
    "We'll remove these in the weighted area joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get all HOLC tracts with census info and find the weighted sum\n",
    "- Find the population contribution that each region makes to the HOLC zone\n",
    "- Find the weighted average of each zone based on population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_values(year, perc=0):\n",
    "    if year<1990:\n",
    "        sql ='''\n",
    "        select * from (select x.*, y.holc_grade, y.city,y.holc_id,\n",
    "        st_area(st_intersection(x.geom,y.geom))/st_area(y.geom)::decimal as holc_perc,\n",
    "        st_area(st_intersection(x.geom,y.geom))/st_area(x.geom)::decimal as census_perc\n",
    "        from\n",
    "        (select distinct a.*,b.geom from census_{} as a, us_tract_{}_conflated_4326 as b\n",
    "        where a.\"gisjoin\" = b.gisjoin) as x, \n",
    "        (select holc_grade, city, id as holc_id, geom from holc_all_dump_4326) as y\n",
    "        where st_intersects(x.geom, y.geom)) as t;\n",
    "        '''.format(year,year)\n",
    "    elif (year==1990 or year==2000 or year==2010):\n",
    "        sql ='''\n",
    "        select * from (select x.*, y.holc_grade, y.city,y.holc_id,\n",
    "        st_area(st_intersection(x.geom,y.geom))/st_area(y.geom)::decimal as holc_perc,\n",
    "        st_area(st_intersection(x.geom,y.geom))/st_area(x.geom)::decimal as census_perc\n",
    "        from\n",
    "        (select distinct a.*,b.geom from census_{} as a, us_blck_grp_{}_4326 as b\n",
    "        where a.\"gisjoin\" = b.gisjoin) as x, \n",
    "        (select holc_grade, city, id as holc_id, geom from holc_all_dump_4326) as y\n",
    "        where st_intersects(x.geom, y.geom)) as t;\n",
    "        '''.format(year,year)\n",
    "    else:\n",
    "        sql ='''\n",
    "        select * from (select x.*, y.holc_grade, y.city,y.holc_id,\n",
    "        st_area(st_intersection(x.geom,y.geom))/st_area(y.geom)::decimal as holc_perc,\n",
    "        st_area(st_intersection(x.geom,y.geom))/st_area(x.geom)::decimal as census_perc\n",
    "        from\n",
    "        (select distinct a.*,b.geom from census_{} as a, us_blck_grp_2010_4326 as b\n",
    "        where a.\"gisjoin\" = b.gisjoin) as x, \n",
    "        (select holc_grade, city, id as holc_id, geom from holc_all_dump_4326) as y\n",
    "        where st_intersects(x.geom, y.geom)) as t;\n",
    "        '''.format(year)\n",
    "        \n",
    "    ### Get all the census units who's area overlap is greater than the min threshold\n",
    "    df_overlay_1 = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )\n",
    "    \n",
    "    ### Create a df that is groups by the HOLC zones\n",
    "    df_overlay=df_overlay_1.groupby(['city','holc_id','holc_grade']).count()[['index']]\n",
    "    df_overlay=df_overlay.rename(columns={'index':'count'})\n",
    "    \n",
    "    ### Get the population for each HOLC zone\n",
    "    df_overlay['population']= df_overlay_1.groupby(['city','holc_id','holc_grade']).apply(lambda x: np.sum(x['population']*x['census_perc']))\n",
    "    \n",
    "    df_overlay_2 = df_overlay_1[df_overlay_1['holc_perc']>perc]\n",
    "    for each in features[year][1:]: \n",
    "        \n",
    "        ### for the other features, use a population-weighted average\n",
    "        weighted_sum = df_overlay_2.groupby(['city','holc_id','holc_grade']).apply(lambda x: np.sum(x[each]*x['population']*x['census_perc'])/ np.sum(x['population']*x['census_perc']))\n",
    "        df_overlay[each]=weighted_sum\n",
    "    df_overlay=df_overlay.fillna(0)\n",
    "    return df_overlay.reset_index(),df_overlay_1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_overlay_geom(df,name):\n",
    "    df_merge = holc_all[['id','geom','city','holc_grade']].merge(df.reset_index(),\n",
    "                   left_on=['city','id'],\n",
    "                   right_on=['city','holc_id']).sort_values(['city','id'])\n",
    "    #### Create the population density meausure\n",
    "    #### Update: Going to convert to geography and gonna do this in postgis \n",
    "    df_merge['population_density']=df_merge['population']/df_merge.geometry.to_crs({'init': 'epsg:3857'}).area\n",
    "    df_merge['geom'] = df_merge['geom'].apply(lambda x: WKTElement(x.wkt, srid=4326))\n",
    "    df_merge.to_sql('{}'.format(name), engine, if_exists='replace', index=False, \n",
    "                             dtype={'geom': Geometry('Polygon', srid= 4326)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {1930:['population','white_perc','colored_perc'],\n",
    "            1940:['population','white_perc','colored_perc'],\n",
    "            1950:['population','white_perc','colored_perc','other_perc','college_perc','median_income_adj'],\n",
    "            1960:['population','white_perc','hispanic_perc','colored_perc','other_perc','college_perc','median_income_adj'],\n",
    "            1970:['population','white_perc','hispanic_perc','colored_perc','other_perc','college_perc','median_income_adj'],\n",
    "            1980:['population','white_perc','colored_perc','hispanic_perc','other_perc','college_perc','median_income_adj','unemployed_perc'],\n",
    "            1990:['population','white_perc','colored_perc','hispanic_perc','other_perc','college_perc','median_income_adj','unemployed_perc'],\n",
    "            2000:['population','white_perc','colored_perc','hispanic_perc','other_perc','college_perc','median_income_adj','unemployed_perc'],\n",
    "            2010:['population','white_perc','colored_perc','hispanic_perc','other_perc','college_perc','median_income_adj','unemployed_perc'],\n",
    "            2016:['population','white_perc','colored_perc','hispanic_perc','other_perc','college_perc','median_income_adj','unemployed_perc']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run for all years and create tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n"
     ]
    }
   ],
   "source": [
    "for y in list(features.keys())[8:9]:\n",
    "    print (y)\n",
    "    if y>=1990:\n",
    "        ### Since we're using block groups in 1990 and onwards, we're using a higher area threshold.\n",
    "        df,df_1 = get_weighted_values(y,perc=0)\n",
    "    else: \n",
    "        df,df_1 = get_weighted_values(y)\n",
    "    merge_overlay_geom(df,'holc_overlay_{}'.format(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Save as files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mapbox import Uploader\n",
    "# service = Uploader()\n",
    "\n",
    "# with open('keys.json') as data_file:    \n",
    "#     mapbox_token = json.load(data_file)\n",
    "# service.session.params['access_token']=mapbox_token['mapbox']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Export to Mapbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each in [\n",
    "#         'holc_overlay_1930',\n",
    "#             'holc_overlay_1940',\n",
    "#             'holc_overlay_1950',\n",
    "#             'holc_overlay_1960',\n",
    "#             'holc_overlay_1970',\n",
    "#             'holc_overlay_1980',\n",
    "#              'holc_overlay_1990',\n",
    "#             'holc_overlay_2000',\n",
    "#             'holc_overlay_2010',\n",
    "#             'holc_overlay_2016'\n",
    "#     ]:\n",
    "#     sql = '''\n",
    "#     select * from {}\n",
    "#     '''.format(each)\n",
    "#     df = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )\n",
    "    \n",
    "#     df.to_file('data/holc_census/{}.geojson'.format(each),driver='GeoJSON')\n",
    "#     with open('data/holc_census/{}.geojson'.format(each), 'rb') as src:\n",
    "#         upload_resp = service.upload(src, '{}'.format(each))\n",
    "# #     upload_resp=service.upload(each,'{}'.format(each))\n",
    "#     print(\"{} done\".format(each))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip is already done once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql = '''\n",
    "# select * from holc_all_dump_4326\n",
    "# '''.format(each)\n",
    "# df = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )\n",
    "\n",
    "# df.to_file('data/holc/holc_all_dump_4326.geojson'.format(each),driver='GeoJSON')\n",
    "# with open('data/holc/holc_all_dump_4326.geojson'.format(each), 'rb') as src:\n",
    "#     upload_resp = service.upload(src, 'holc_all_dump_4326'.format(each))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Export to CARTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartoframes\n",
    "from cartoframes import Layer, BaseMap, styling, CartoContext,Credentials\n",
    "\n",
    "cc = CartoContext()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.GeoDataFrame.from_postgis(\"select * from holc_overlay_1930\", conn,crs={'init':'epsg:4326'}, geom_col='geom' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holc_overlay_1930 done\n",
      "holc_overlay_1940 done\n",
      "holc_overlay_1950 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method Collection.__del__ of <open Collection '/Users/wenfeixu/Documents/GITHUB/redlining/holc_census/holc_overlay_1930:holc_overlay_1930', mode 'w' at 0x12cb86e48>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wenfeixu/anaconda2/envs/geo_wenfei/lib/python3.6/site-packages/fiona/collection.py\", line 426, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/wenfeixu/anaconda2/envs/geo_wenfei/lib/python3.6/site-packages/fiona/collection.py\", line 403, in close\n",
      "    self.flush()\n",
      "  File \"/Users/wenfeixu/anaconda2/envs/geo_wenfei/lib/python3.6/site-packages/fiona/collection.py\", line 393, in flush\n",
      "    self.session.sync(self)\n",
      "  File \"fiona/ogrext.pyx\", line 1051, in fiona.ogrext.WritingSession.sync\n",
      "ValueError: Null data source\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holc_overlay_1960 done\n",
      "holc_overlay_1970 done\n",
      "holc_overlay_1980 done\n",
      "holc_overlay_1990 done\n",
      "holc_overlay_2000 done\n",
      "holc_overlay_2010 done\n",
      "holc_overlay_2016 done\n"
     ]
    }
   ],
   "source": [
    "df1= []\n",
    "for each in [\n",
    "        'holc_overlay_1930',\n",
    "            'holc_overlay_1940',\n",
    "            'holc_overlay_1950',\n",
    "            'holc_overlay_1960',\n",
    "            'holc_overlay_1970',\n",
    "            'holc_overlay_1980',\n",
    "            'holc_overlay_1990',\n",
    "            'holc_overlay_2000',\n",
    "            'holc_overlay_2010',\n",
    "            'holc_overlay_2016'\n",
    "    ]:\n",
    "\n",
    "    sql = '''\n",
    "    select * from {}\n",
    "    '''.format(each)\n",
    "    df = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )\n",
    "#     print(each.split('_new')[0])\n",
    "#     cc.write(df,'{}'.format(each),overwrite=True)\n",
    "    df.to_file('data/holc_census/{}'.format(each))\n",
    "    print(\"{} done\".format(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "select * from holc_all_dump_4326_new\n",
    "'''.format(each)\n",
    "df = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )\n",
    "# cc.write(df,'holc_all_dump_4326',overwrite=True)\n",
    "df.to_file('data/holc/holc_zones')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join all the tables across all the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select * from holc_overlay_1930'\n",
    "df_1930 = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )\n",
    "\n",
    "sql = 'select * from holc_overlay_1940'\n",
    "df_1940 = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )\n",
    "sql = 'select * from holc_overlay_1950'\n",
    "df_1950 = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )\n",
    "sql = 'select * from holc_overlay_1960'\n",
    "df_1960 = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )\n",
    "sql = 'select * from holc_overlay_1970'\n",
    "df_1970 = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )\n",
    "sql = 'select * from holc_overlay_1980'\n",
    "df_1980 = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )\n",
    "sql = 'select * from holc_overlay_1990'\n",
    "df_1990 = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )\n",
    "sql = 'select * from holc_overlay_2000'\n",
    "df_2000 = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )\n",
    "sql = 'select * from holc_overlay_2010'\n",
    "df_2010 = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )\n",
    "sql = 'select * from holc_overlay_2016'\n",
    "df_2016 = gpd.GeoDataFrame.from_postgis(sql, conn,crs={'init':'epsg:4326'}, geom_col='geom' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3057467459904005"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016[df_2016['city']=='Los Angeles']['other_perc'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1930['year']=np.full((df_1930.shape[0], 1),1930)\n",
    "df_1940['year']=np.full((df_1940.shape[0], 1),1940)\n",
    "df_1950['year']=np.full((df_1950.shape[0], 1),1950)\n",
    "df_1960['year']=np.full((df_1960.shape[0], 1),1960)\n",
    "df_1970['year']=np.full((df_1970.shape[0], 1),1970)\n",
    "df_1980['year']=np.full((df_1980.shape[0], 1),1980)\n",
    "df_1990['year']=np.full((df_1990.shape[0], 1),1990)\n",
    "df_2000['year']=np.full((df_2000.shape[0], 1),2000)\n",
    "df_2010['year']=np.full((df_2010.shape[0], 1),2010)\n",
    "df_2016['year']=np.full((df_2016.shape[0], 1),2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=  pd.concat([df_1930,df_1940,df_1950,df_1960,df_1970,df_1980,df_1990,df_2000,df_2010,df_2016])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenfeixu/anaconda2/envs/geo_wenfei/lib/python3.6/site-packages/carto/resources.py:90: FutureWarning: This is part of a non-public CARTO API and may change in the future. Take this into account if you are using this in a production environment\n",
      "  warnings.warn('This is part of a non-public CARTO API and may change in the future. Take this into account if you are using this in a production environment', FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table successfully written to CARTO: https://wxu-carto.carto.com/dataset/holc_overlay_all\n"
     ]
    }
   ],
   "source": [
    "cc.write(df_all,'holc_overlay_all',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to postgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['geom'] = df_all['geom'].apply(lambda x: WKTElement(x.wkt, srid=4326))\n",
    "df_all.to_sql('holc_overlay_all', engine, if_exists='replace', index=False, \n",
    "                         dtype={'geom': Geometry('Polygon', srid= 4326)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "college_perc             0.324017\n",
       "colored_perc             0.776885\n",
       "count                   11.000000\n",
       "hispanic_perc            0.019168\n",
       "holc_id               2731.000000\n",
       "id                    2731.000000\n",
       "index                 1906.000000\n",
       "median_income_adj    27482.117665\n",
       "other_perc               0.028902\n",
       "population            3020.284074\n",
       "unemployed_perc          0.088385\n",
       "white_perc               0.177355\n",
       "year                  2010.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[(df_all.city=='Dayton')&(df_all.holc_grade_x=='D')&(df_all.year==1960)].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['population_density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
